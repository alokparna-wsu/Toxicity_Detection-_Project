# Toxicity Detection in the Context of Social Media Discussions using NLP

This is a project on Toxicity Detection in the Context of Social Media Discussions for detection and identification of toxic comments using both machine learning models and deep learning models.

The dataset used in this project is the Jigsaw/Conversation AI dataset provided for the Kaggle Toxic Comment Classification Challenge. It contains a large number of Wikipedia comments which have been labelled by human raters for toxic behaviour.	

Machine learning classification models like Logistic Regression, Support Vector Machine and XGBoost are used on the word embedded vectors and their accuracies are compared.

Performance of the classifier is then further increased by using Recurrent Neural Network architectures in the field of deep learning like Long Short-Term Memory (LSTM) classifier, Bi-directional GRU (Gated Recurrent Unit) and Pooled GRU are used and the results are compared.

Installations:
Python >= 3.7
Tensorflow >= 2.1

Dataset location: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data

Download the GloVe, Word2Vec and FastText embedding files from their repositories.
